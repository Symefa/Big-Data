{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Pengenalan Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets: [NYS Motor Vehicle Crashes and Insurance Reduction](https://www.kaggle.com/new-york-state/nys-motor-vehicle-crashes-and-insurance-reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x0000000006DDD358>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895916"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = spark.read.csv(\"C:/Users/Symefa/Desktop/Big-Data/datasets/crash.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Fix\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Crash Descriptor: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Day of Week: string (nullable = true)\n",
      " |-- Police Report: string (nullable = true)\n",
      " |-- Lighting Conditions: string (nullable = true)\n",
      " |-- Municipality: string (nullable = true)\n",
      " |-- Collision Type Descriptor: string (nullable = true)\n",
      " |-- County Name: string (nullable = true)\n",
      " |-- Road Descriptor: string (nullable = true)\n",
      " |-- Weather Conditions: string (nullable = true)\n",
      " |-- Traffic Control Device: string (nullable = true)\n",
      " |-- Road Surface Conditions: string (nullable = true)\n",
      " |-- DOT Reference Marker Location: string (nullable = true)\n",
      " |-- Pedestrian Bicyclist Action: string (nullable = true)\n",
      " |-- Event Descriptor: string (nullable = true)\n",
      " |-- Number of Vehicles Involved: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting To SparkSQL Datatype\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView('crashes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "| County Name|\n",
      "+------------+\n",
      "|      FULTON|\n",
      "|ST. LAWRENCE|\n",
      "| CATTARAUGUS|\n",
      "|     STEUBEN|\n",
      "|       YATES|\n",
      "|       KINGS|\n",
      "|      OSWEGO|\n",
      "|     MADISON|\n",
      "|   JEFFERSON|\n",
      "|  CHAUTAUQUA|\n",
      "| SCHENECTADY|\n",
      "|      WARREN|\n",
      "|    ROCKLAND|\n",
      "|       TIOGA|\n",
      "|    ALLEGANY|\n",
      "|      MONROE|\n",
      "|      SENECA|\n",
      "|    ONONDAGA|\n",
      "|       LEWIS|\n",
      "|      QUEENS|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT `County Name` FROM crashes\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mining Process\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Banyak Kecelakaan per daerah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|     County|Number of Accident|\n",
      "+-----------+------------------+\n",
      "|     NASSAU|             98984|\n",
      "|    SUFFOLK|             95967|\n",
      "|     QUEENS|             59875|\n",
      "|      KINGS|             58611|\n",
      "|       ERIE|             51708|\n",
      "|WESTCHESTER|             44336|\n",
      "|     MONROE|             42098|\n",
      "|   NEW YORK|             35752|\n",
      "|      BRONX|             32411|\n",
      "|   ONONDAGA|             29183|\n",
      "|     ORANGE|             28860|\n",
      "|     ALBANY|             24543|\n",
      "|   ROCKLAND|             19754|\n",
      "|   DUTCHESS|             17181|\n",
      "|   SARATOGA|             14138|\n",
      "|     ONEIDA|             13215|\n",
      "|     ULSTER|             12909|\n",
      "|     BROOME|             11794|\n",
      "|   RICHMOND|             11486|\n",
      "|    NIAGARA|             11170|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT `County Name` AS County, COUNT(`County Name`) AS `Number of Accident`\\\n",
    "          FROM crashes \\\n",
    "          GROUP BY `County Name` \\\n",
    "          ORDER BY COUNT(`County Name`) DESC \\\n",
    "          \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ranking kecelakaan terjadi pada jam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| Time|Jumlah|\n",
      "+-----+------+\n",
      "| 0:00| 28527|\n",
      "|17:00|  7615|\n",
      "|16:00|  7379|\n",
      "|18:00|  7245|\n",
      "|15:00|  7187|\n",
      "|17:30|  6396|\n",
      "|14:00|  6300|\n",
      "|12:00|  6000|\n",
      "|13:00|  5890|\n",
      "| 8:00|  5632|\n",
      "|16:30|  5621|\n",
      "|19:00|  5505|\n",
      "|15:30|  5387|\n",
      "|11:00|  5387|\n",
      "|10:00|  5320|\n",
      "| 9:00|  5295|\n",
      "|14:30|  5139|\n",
      "|18:30|  5076|\n",
      "|12:30|  4690|\n",
      "|13:30|  4539|\n",
      "+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT `Time`, COUNT(`Time`) AS Jumlah \\\n",
    "          FROM crashes  \\\n",
    "          GROUP BY `Time` \\\n",
    "          ORDER BY Jumlah DESC \\\n",
    "          \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Jumlah Kecelakan berbasis dari Deskripsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|    Event Descriptor|Jumlah|\n",
      "+--------------------+------+\n",
      "|Other Motor Vehic...|609589|\n",
      "|                Deer| 68012|\n",
      "|Pedestrian, Colli...| 41109|\n",
      "|Guide Rail - Not ...| 24171|\n",
      "|Earth Embankment/...| 20633|\n",
      "|Light Support/Uti...| 18120|\n",
      "|Bicyclist, Collis...| 17289|\n",
      "|Tree, Collision W...| 17224|\n",
      "|Other Fixed Objec...|  9429|\n",
      "|Animal, Collision...|  8510|\n",
      "|Other Object (Not...|  8045|\n",
      "|Sign Post, Collis...|  7727|\n",
      "|Building/Wall, Co...|  5286|\n",
      "|Other*, Non-Colli...|  5222|\n",
      "|Curbing, Collisio...|  5159|\n",
      "|Snow Embankment, ...|  4788|\n",
      "|Overturned, Non-C...|  3707|\n",
      "|Barrier, Collisio...|  3568|\n",
      "|Fence, Collision ...|  3178|\n",
      "|Median - Not At E...|  2564|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT `Event Descriptor`, COUNT(`Event Descriptor`) AS Jumlah \\\n",
    "          FROM crashes  \\\n",
    "          GROUP BY `Event Descriptor` \\\n",
    "          ORDER BY Jumlah DESC \\\n",
    "          \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
